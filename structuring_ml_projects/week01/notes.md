# Week 1

## Why ML Strategy

TODO:

## Orthogonalization

TODO:

## Single number evaluation metric

TODO:

## Satisficing and Optimizing Metric

TODO:

## Train/dev/test distributions

TODO:

## Size of the dev and test sets

TODO:

## When to change dev/test sets and metrics

TODO:

## Why human-level Performance?

1- ML Algos can compete w/ humans
2- The workflow is much more efficient

Bayes Optimal Error - the best possible function to map from x -> y

## Avoidable Bias

Avoidable Bias: Difference between Bayes error & training error
Variance Problem: Difference between training error and testing error

## Understanding Human-Level performance

- HL error acts as a proxy for Bayes error, and is normally very close to Bayes
error
- Human level performance depends on the human
  - e.g. Child < Doctor < Team of Doctors
- If we know Team of Doctors can get 0.5% error, Bayes error should be <0.5%
- Use every known Human Level performace as a goal post

## Surpassing Human Level Performance

Once passing Human Level Error, avoidable bias is hard to calculate
- We cannot know Bayes Error

## Improving your model performance

TODO:

## References
