# Week 4

## Learning to predict the next word

TODO:

## A brief diversion into cognitive science

TODO:

## Another diversion: The softmax output function

- A way of forcing the output of a NN to sum to 1

The sq. err method has drawbacks
- If desired output is 1 and output is 1e-10, there is almost no gradient
- Not very good for mutually exclusive classes

## Neuro-probabilistic language models

TODO:

## Ways to deal with the large number of possible outputs

TODO:

## References
